\chapter*{引言}

支持向量机是目前最高效的有监督机器学习算法之一。这意味着当您遇到问题并尝试在其上运行SVM时，您通常会得到非常好的结果，而无需进行很多调整。尽管如此，因为它基于强大的数学背景，它经常被视为一个黑盒子。在本书中，我们将深入讨论SVM背后的主要思想。有几种支持向量机，这就是为什么我经常提到支持向量机。本书的目标是了解它们是如何工作的。

支持向量机是几个人多年工作的结果。第一个SVM算法是Vladimir Vapnik在1963年提出的。他后来与Alexey Chervonenkis就\href{https://en.wikipedia.org/wiki/Vapnik–Chervonenkis_theory}{VC理论}进行了密切的合作，VC理论试图从统计学的角度解释学习过程，他们都对支持向量机做出了巨大的贡献。你可以在\href{http://www.svms.org/history.html}{这里}找到支持向量机的详细历史。

在现实生活中，支持向量机已成功应用于三个主要领域:文本分类、图像识别和生物信息学(Cristianini \& Shawe-Taylor, 2000)。具体的例子包括分类新闻报道、手写数字识别和癌症组织样本。

在第一章中，我们将了解重要的概念:向量、线性可分性和超平面。它们是让您理解支持向量机的基础知识。在第二章中，我们将学习一种称为感知器的简单算法，而不是直接进入这个主题。不要跳过它——尽管它没有讨论支持向量机，本章将给您提供宝贵的见解，解释为什么支持向量机更擅长分类数据。

第三章将逐步构建所谓的支持向量机优化问题。第4章可能是最难的，它将向您展示如何解决这个问题——首先用数学方法，然后用编程方法。在第五章中，我们将发现一种新的支持向量机，称为软间隔支持向量机。我们将看到它是如何对原来的问题进行改进的。

第6章将介绍核，并解释所谓的“核技巧”。有了这个技巧，我们将得到目前最常用的核函数SVM。在第七章中，我们将学习SMO，这是一种专门为快速解决SVM优化问题而创建的算法。在第8章中，我们将看到支持向量机可以用于对多个类别的样本进行分类。

现在让我们开始我们的旅程。